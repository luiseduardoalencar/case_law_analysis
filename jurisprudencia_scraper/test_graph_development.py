#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Script de teste para validar desenvolvimento das Etapas 1 e 2
Testa modelos de dados e preprocessamento
"""

import os
import sys
import time
from pathlib import Path
from datetime import datetime
from typing import Dict, List, Any

# Adiciona src ao path
project_root = Path(__file__).parent
src_path = project_root / "src"
sys.path.insert(0, str(src_path))

# Configura√ß√µes b√°sicas
os.environ['TZ'] = 'America/Sao_Paulo'

def print_section(title: str):
    """Imprime se√ß√£o formatada"""
    print(f"\n{'='*80}")
    print(f"üîç {title}")
    print(f"{'='*80}")

def print_subsection(title: str):
    """Imprime subse√ß√£o formatada"""
    print(f"\n{'-'*60}")
    print(f"üìã {title}")
    print(f"{'-'*60}")

def print_success(message: str):
    """Imprime mensagem de sucesso"""
    print(f"‚úÖ {message}")

def print_error(message: str):
    """Imprime mensagem de erro"""
    print(f"‚ùå {message}")

def print_warning(message: str):
    """Imprime mensagem de aviso"""
    print(f"‚ö†Ô∏è {message}")

def print_info(message: str):
    """Imprime mensagem informativa"""
    print(f"‚ÑπÔ∏è {message}")

def test_imports():
    """Testa importa√ß√£o de todos os m√≥dulos"""
    print_section("TESTE DE IMPORTA√á√ïES")
    
    import_tests = [
        ("graph.models.nodes", "Modelos de N√≥s"),
        ("graph.models.edges", "Modelos de Arestas"),
        ("graph.models.graph_schema", "Schema do Grafo"),
        ("graph.pipeline.preprocessing", "Pipeline de Preprocessamento")
    ]
    
    results = {}
    
    for module_name, description in import_tests:
        try:
            module = __import__(module_name, fromlist=[''])
            print_success(f"{description}: {module_name}")
            results[module_name] = True
        except ImportError as e:
            print_error(f"{description}: {e}")
            results[module_name] = False
        except Exception as e:
            print_error(f"{description}: Erro inesperado - {e}")
            results[module_name] = False
    
    return results

def test_node_models():
    """Testa modelos de n√≥s"""
    print_section("TESTE DOS MODELOS DE N√ìS")
    
    try:
        from graph.models.nodes import (
            DocumentNode, SectionNode, EntityNode, ConceptNode,
            NodeType, SectionType, EntityType,
            create_document_node_from_db_row, CONCEITOS_JURIDICOS_PREDEFINIDOS
        )
        
        results = {}
        
        # Teste 1: Cria√ß√£o de DocumentNode
        print_subsection("Teste DocumentNode")
        try:
            doc = DocumentNode(
                id="test_doc_001",
                numero_processo="0001234-56.2023.8.18.0001",
                url_original="https://exemplo.com",
                orgao_julgador="1¬™ Vara C√≠vel",
                relator="Des. Jo√£o Silva",
                conteudo_limpo="Este √© um texto de teste para validar o documento.",
                num_tokens=12
            )
            
            print_success(f"DocumentNode criado: {doc.id}")
            print_info(f"  - N√∫mero do processo: {doc.numero_processo}")
            print_info(f"  - √ìrg√£o julgador: {doc.orgao_julgador}")
            print_info(f"  - N√∫mero de tokens: {doc.num_tokens}")
            
            # Testa m√©todos
            doc.add_secao("sec_001")
            doc.add_entidade("ent_001")
            doc.add_conceito("con_001")
            
            print_info(f"  - Se√ß√µes: {doc.secoes_ids}")
            print_info(f"  - Entidades: {doc.entidades_ids}")
            print_info(f"  - Conceitos: {doc.conceitos_ids}")
            
            # Testa serializa√ß√£o
            doc_dict = doc.to_dict()
            print_info(f"  - Serializa√ß√£o: {len(doc_dict)} campos")
            
            results['DocumentNode'] = True
            
        except Exception as e:
            print_error(f"Erro ao testar DocumentNode: {e}")
            results['DocumentNode'] = False
        
        # Teste 2: Cria√ß√£o de SectionNode
        print_subsection("Teste SectionNode")
        try:
            section = SectionNode(
                id="sec_test_001",
                parent_document_id="test_doc_001",
                section_type=SectionType.DECISAO,
                conteudo_texto="Esta √© uma decis√£o judicial de teste.",
                ordem=1
            )
            
            print_success(f"SectionNode criado: {section.id}")
            print_info(f"  - Tipo: {section.section_type.value}")
            print_info(f"  - Documento pai: {section.parent_document_id}")
            print_info(f"  - Ordem: {section.ordem}")
            
            results['SectionNode'] = True
            
        except Exception as e:
            print_error(f"Erro ao testar SectionNode: {e}")
            results['SectionNode'] = False
        
        # Teste 3: Cria√ß√£o de EntityNode
        print_subsection("Teste EntityNode")
        try:
            entity = EntityNode(
                id="ent_test_001",
                entity_type=EntityType.JUIZ,
                nome_original="Des. Jo√£o Silva",
                nome_normalizado="jo√£o silva",
                frequencia_global=5
            )
            
            entity.add_variacao("Jo√£o Silva")
            entity.add_variacao("Desembargador Jo√£o Silva")
            entity.incrementar_frequencia()
            
            print_success(f"EntityNode criado: {entity.id}")
            print_info(f"  - Tipo: {entity.entity_type.value}")
            print_info(f"  - Nome normalizado: {entity.nome_normalizado}")
            print_info(f"  - Frequ√™ncia: {entity.frequencia_global}")
            print_info(f"  - Varia√ß√µes: {entity.variacoes}")
            
            results['EntityNode'] = True
            
        except Exception as e:
            print_error(f"Erro ao testar EntityNode: {e}")
            results['EntityNode'] = False
        
        # Teste 4: Cria√ß√£o de ConceptNode
        print_subsection("Teste ConceptNode")
        try:
            concept = ConceptNode(
                id="con_test_001",
                termo_conceito="empr√©stimo consignado",
                categoria_juridica="direito banc√°rio",
                frequencia_global=15
            )
            
            concept.add_contexto("Contrato de empr√©stimo consignado em folha de pagamento")
            concept.add_documento("test_doc_001", 0.85)
            concept.set_pmi_score("con_test_002", 0.7)
            
            print_success(f"ConceptNode criado: {concept.id}")
            print_info(f"  - Termo: {concept.termo_conceito}")
            print_info(f"  - Categoria: {concept.categoria_juridica}")
            print_info(f"  - Frequ√™ncia: {concept.frequencia_global}")
            print_info(f"  - Contextos: {len(concept.contextos)}")
            print_info(f"  - Scores TF-IDF: {concept.tfidf_scores}")
            print_info(f"  - Scores PMI: {concept.pmi_scores}")
            
            results['ConceptNode'] = True
            
        except Exception as e:
            print_error(f"Erro ao testar ConceptNode: {e}")
            results['ConceptNode'] = False
        
        # Teste 5: Conceitos jur√≠dicos predefinidos
        print_subsection("Teste Conceitos Jur√≠dicos Predefinidos")
        try:
            print_info(f"Total de conceitos predefinidos: {len(CONCEITOS_JURIDICOS_PREDEFINIDOS)}")
            print_info("Alguns conceitos:")
            for i, conceito in enumerate(CONCEITOS_JURIDICOS_PREDEFINIDOS[:5]):
                print_info(f"  {i+1}. {conceito}")
            
            # Verifica se tem conceitos espec√≠ficos de empr√©stimo consignado
            conceitos_consignado = [c for c in CONCEITOS_JURIDICOS_PREDEFINIDOS 
                                  if 'consignado' in c.lower()]
            print_info(f"Conceitos relacionados a consignado: {conceitos_consignado}")
            
            results['ConceptosJuridicos'] = True
            
        except Exception as e:
            print_error(f"Erro ao testar conceitos jur√≠dicos: {e}")
            results['ConceptosJuridicos'] = False
        
        return results
        
    except ImportError as e:
        print_error(f"Erro de importa√ß√£o nos modelos de n√≥s: {e}")
        return {}

def test_edge_models():
    """Testa modelos de arestas"""
    print_section("TESTE DOS MODELOS DE ARESTAS")
    
    try:
        from graph.models.edges import (
            SimilarityEdge, RelevanceEdge, CooccurrenceEdge, HierarchicalEdge,
            EdgeType, SimilarityType,
            create_similarity_matrix_edges, validate_edge_weights
        )
        import numpy as np
        
        results = {}
        
        # Teste 1: SimilarityEdge
        print_subsection("Teste SimilarityEdge")
        try:
            sim_edge = SimilarityEdge.create_document_similarity(
                "doc_001", "doc_002", 0.85, "sentence-transformers", 0.9
            )
            
            print_success(f"SimilarityEdge criado: {sim_edge.id}")
            print_info(f"  - Fonte: {sim_edge.source_node_id}")
            print_info(f"  - Destino: {sim_edge.target_node_id}")
            print_info(f"  - Peso: {sim_edge.weight}")
            print_info(f"  - Score cossenos: {sim_edge.cosine_score}")
            print_info(f"  - Modelo: {sim_edge.embedding_model}")
            
            # Testa tuple para NetworkX
            edge_tuple = sim_edge.get_tuple()
            print_info(f"  - Tupla NetworkX: {len(edge_tuple)} elementos")
            
            results['SimilarityEdge'] = True
            
        except Exception as e:
            print_error(f"Erro ao testar SimilarityEdge: {e}")
            results['SimilarityEdge'] = False
        
        # Teste 2: RelevanceEdge
        print_subsection("Teste RelevanceEdge")
        try:
            rel_edge = RelevanceEdge.create_document_concept_relevance(
                "doc_001", "con_001", 0.45, 5, 10, 0.69, 100
            )
            
            print_success(f"RelevanceEdge criado: {rel_edge.id}")
            print_info(f"  - Peso (TF-IDF): {rel_edge.weight}")
            print_info(f"  - Term Frequency: {rel_edge.term_frequency}")
            print_info(f"  - Document Frequency: {rel_edge.document_frequency}")
            print_info(f"  - IDF: {rel_edge.inverse_document_frequency}")
            
            results['RelevanceEdge'] = True
            
        except Exception as e:
            print_error(f"Erro ao testar RelevanceEdge: {e}")
            results['RelevanceEdge'] = False
        
        # Teste 3: CooccurrenceEdge
        print_subsection("Teste CooccurrenceEdge")
        try:
            cooc_edge = CooccurrenceEdge.create_concept_cooccurrence(
                "con_001", "con_002", 1.25, 15, 50, 40, 1000, 10
            )
            
            print_success(f"CooccurrenceEdge criado: {cooc_edge.id}")
            print_info(f"  - Peso (PMI): {cooc_edge.weight}")
            print_info(f"  - Frequ√™ncia conjunta: {cooc_edge.joint_frequency}")
            print_info(f"  - Total janelas: {cooc_edge.total_windows}")
            print_info(f"  - Tamanho janela: {cooc_edge.window_size}")
            
            results['CooccurrenceEdge'] = True
            
        except Exception as e:
            print_error(f"Erro ao testar CooccurrenceEdge: {e}")
            results['CooccurrenceEdge'] = False
        
        # Teste 4: HierarchicalEdge
        print_subsection("Teste HierarchicalEdge")
        try:
            hier_edge = HierarchicalEdge.create_document_section(
                "doc_001", "sec_001", 1
            )
            
            print_success(f"HierarchicalEdge criado: {hier_edge.id}")
            print_info(f"  - Peso: {hier_edge.weight}")
            print_info(f"  - Tipo hierarquia: {hier_edge.hierarchy_type}")
            print_info(f"  - Ordem: {hier_edge.order}")
            
            results['HierarchicalEdge'] = True
            
        except Exception as e:
            print_error(f"Erro ao testar HierarchicalEdge: {e}")
            results['HierarchicalEdge'] = False
        
        # Teste 5: Valida√ß√£o de pesos
        print_subsection("Teste Valida√ß√£o de Arestas")
        try:
            edges = [sim_edge, rel_edge, cooc_edge, hier_edge]
            stats = validate_edge_weights(edges)
            
            print_success("Valida√ß√£o de pesos executada")
            for edge_type, edge_stats in stats.items():
                print_info(f"  - {edge_type}: {edge_stats}")
            
            results['EdgeValidation'] = True
            
        except Exception as e:
            print_error(f"Erro ao testar valida√ß√£o: {e}")
            results['EdgeValidation'] = False
        
        return results
        
    except ImportError as e:
        print_error(f"Erro de importa√ß√£o nos modelos de arestas: {e}")
        return {}

def test_graph_schema():
    """Testa schema do grafo"""
    print_section("TESTE DO SCHEMA DO GRAFO")
    
    try:
        from graph.models.graph_schema import (
            GraphConfiguration, GraphSchema, GraphStatistics,
            GraphValidationLevel, create_default_schema, create_optimized_schema,
            DEVELOPMENT_CONFIG, PRODUCTION_CONFIG
        )
        import networkx as nx
        
        results = {}
        
        # Teste 1: Configura√ß√£o padr√£o
        print_subsection("Teste GraphConfiguration")
        try:
            config = GraphConfiguration()
            config_dict = config.to_dict()
            
            print_success("GraphConfiguration criada")
            print_info(f"  - Similarity threshold: {config.similarity_thresholds}")
            print_info(f"  - Relevance threshold: {config.relevance_threshold}")
            print_info(f"  - PMI threshold: {config.pmi_threshold}")
            print_info(f"  - Embedding model: {config.embedding_model}")
            print_info(f"  - Chunk size: {config.chunk_size}")
            print_info(f"  - Valida√ß√£o: {config.validation_level.value}")
            
            results['GraphConfiguration'] = True
            
        except Exception as e:
            print_error(f"Erro ao testar GraphConfiguration: {e}")
            results['GraphConfiguration'] = False
        
        # Teste 2: Schema padr√£o
        print_subsection("Teste GraphSchema")
        try:
            schema = create_default_schema()
            
            print_success("GraphSchema criado")
            print_info(f"  - Tipos de n√≥s permitidos: {len(schema.allowed_node_types)}")
            print_info(f"  - Rela√ß√µes permitidas: {len(schema.allowed_edge_types)}")
            
            # Testa otimiza√ß√£o para 3000 documentos
            optimized_config = schema.optimize_config_for_size(3000)
            print_info(f"  - Config otimizada para 3000 docs:")
            print_info(f"    * Similarity: {optimized_config.similarity_thresholds}")
            print_info(f"    * Max edges: {optimized_config.max_similarity_edges_per_document}")
            
            results['GraphSchema'] = True
            
        except Exception as e:
            print_error(f"Erro ao testar GraphSchema: {e}")
            results['GraphSchema'] = False
        
        # Teste 3: Estat√≠sticas
        print_subsection("Teste GraphStatistics")
        try:
            # Cria um grafo simples para testar
            G = nx.Graph()
            G.add_node("doc_1", node_type="document")
            G.add_node("doc_2", node_type="document")
            G.add_node("sec_1", node_type="section")
            G.add_edge("doc_1", "doc_2", edge_type="similarity", weight=0.8)
            G.add_edge("doc_1", "sec_1", edge_type="hierarchical", weight=1.0)
            
            stats = GraphStatistics()
            stats.update_from_networkx(G)
            
            print_success("GraphStatistics calculadas")
            print_info(f"  - Total n√≥s: {stats.total_nodes}")
            print_info(f"  - Total arestas: {stats.total_edges}")
            print_info(f"  - Densidade: {stats.density:.4f}")
            print_info(f"  - Grau m√©dio: {stats.average_degree:.2f}")
            print_info(f"  - Componentes: {stats.num_connected_components}")
            
            stats_dict = stats.to_dict()
            print_info(f"  - Serializa√ß√£o: {len(stats_dict)} campos principais")
            
            results['GraphStatistics'] = True
            
        except Exception as e:
            print_error(f"Erro ao testar GraphStatistics: {e}")
            results['GraphStatistics'] = False
        
        # Teste 4: Configura√ß√µes predefinidas
        print_subsection("Teste Configura√ß√µes Predefinidas")
        try:
            configs = {
                'DEVELOPMENT': DEVELOPMENT_CONFIG,
                'PRODUCTION': PRODUCTION_CONFIG
            }
            
            for name, config in configs.items():
                print_success(f"Config {name} carregada")
                print_info(f"  - Similarity threshold: {config.similarity_thresholds}")
                print_info(f"  - Max edges: {config.max_similarity_edges_per_document}")
                print_info(f"  - Validation: {config.validation_level.value}")
            
            results['PredefinedConfigs'] = True
            
        except Exception as e:
            print_error(f"Erro ao testar configura√ß√µes predefinidas: {e}")
            results['PredefinedConfigs'] = False
        
        return results
        
    except ImportError as e:
        print_error(f"Erro de importa√ß√£o no schema: {e}")
        return {}

def test_preprocessing():
    """Testa o preprocessamento"""
    print_section("TESTE DO PREPROCESSAMENTO")
    
    try:
        from graph.pipeline.preprocessing import (
            DatabaseLoader, TextCleaner, JurisprudenciaPreprocessor,
            preprocess_jurisprudencias, get_sample_documents
        )
        
        results = {}
        
        # Teste 1: TextCleaner
        print_subsection("Teste TextCleaner")
        try:
            cleaner = TextCleaner()
            
            # Testa limpeza de HTML
            html_content = """
            <div>
                <h1>AC√ìRD√ÉO</h1>
                <p>EMENTA: Este √© um <strong>teste</strong> de limpeza de HTML.</p>
                <script>alert('test');</script>
                <style>body { color: blue; }</style>
            </div>
            """
            
            clean_text = cleaner.extract_clean_text(html_content)
            
            print_success("TextCleaner funcionando")
            print_info(f"  - HTML original: {len(html_content)} chars")
            print_info(f"  - Texto limpo: {len(clean_text)} chars")
            print_info(f"  - Amostra: {clean_text[:100]}...")
            
            # Testa valida√ß√£o
            is_valid = cleaner.is_valid_document(clean_text)
            print_info(f"  - Documento v√°lido: {is_valid}")
            
            results['TextCleaner'] = True
            
        except Exception as e:
            print_error(f"Erro ao testar TextCleaner: {e}")
            results['TextCleaner'] = False
        
        # Teste 2: DatabaseLoader
        print_subsection("Teste DatabaseLoader")
        try:
            # Testa conex√£o com banco (sem executar queries pesadas)
            loader = DatabaseLoader()
            
            print_success("DatabaseLoader inicializado")
            print_info(f"  - Engine criado: {loader.engine is not None}")
            print_info(f"  - Session criada: {loader.Session is not None}")
            
            loader.close()
            print_info("  - Conex√£o fechada com sucesso")
            
            results['DatabaseLoader'] = True
            
        except Exception as e:
            print_error(f"Erro ao testar DatabaseLoader: {e}")
            print_warning("  - Isso pode ser normal se o banco n√£o estiver rodando")
            results['DatabaseLoader'] = False
        
        # Teste 3: Preprocessor (sem banco)
        print_subsection("Teste JurisprudenciaPreprocessor (Mock)")
        try:
            # Cria dados mock para testar l√≥gica
            from graph.models.nodes import DocumentNode
            from graph.pipeline.preprocessing import PreprocessingStats
            
            # Simula resultado do preprocessamento
            mock_doc = DocumentNode(
                id="doc_test_001",
                numero_processo="0001234-56.2023.8.18.0001",
                url_original="https://test.com",
                conteudo_limpo="Este √© um documento de teste para valida√ß√£o.",
                num_tokens=10
            )
            
            mock_stats = PreprocessingStats(
                total_documents=1,
                valid_documents=1,
                documents_with_content=1,
                total_characters=50,
                total_words=10
            )
            mock_stats.update_averages()
            
            print_success("Mock do preprocessamento criado")
            print_info(f"  - Documento: {mock_doc.id}")
            print_info(f"  - Estat√≠sticas: {mock_stats.total_documents} docs")
            print_info(f"  - M√©dia de caracteres: {mock_stats.average_document_length}")
            
            # Testa serializa√ß√£o das estat√≠sticas
            stats_dict = mock_stats.to_dict()
            print_info(f"  - Stats serializadas: {len(stats_dict)} campos")
            
            results['JurisprudenciaPreprocessor'] = True
            
        except Exception as e:
            print_error(f"Erro ao testar preprocessor: {e}")
            results['JurisprudenciaPreprocessor'] = False
        
        return results
        
    except ImportError as e:
        print_error(f"Erro de importa√ß√£o no preprocessamento: {e}")
        return {}

def test_integration():
    """Testa integra√ß√£o entre m√≥dulos"""
    print_section("TESTE DE INTEGRA√á√ÉO")
    
    try:
        from graph.models.nodes import DocumentNode, SectionNode
        from graph.models.edges import SimilarityEdge, HierarchicalEdge
        from graph.models.graph_schema import create_optimized_schema
        from graph.pipeline.preprocessing import PreprocessingStats
        
        results = {}
        
        # Teste 1: Pipeline completo simulado
        print_subsection("Teste Pipeline Simulado")
        try:
            # Cria schema otimizado
            schema = create_optimized_schema(100)  # 100 documentos de teste
            
            # Cria alguns n√≥s
            doc1 = DocumentNode(
                id="doc_001",
                numero_processo="0001234-56.2023.8.18.0001",
                url_original="https://test1.com",
                conteudo_limpo="Primeiro documento sobre empr√©stimo consignado.",
                relator="Des. Jo√£o Silva"
            )
            
            doc2 = DocumentNode(
                id="doc_002", 
                numero_processo="0001235-56.2023.8.18.0001",
                url_original="https://test2.com",
                conteudo_limpo="Segundo documento sobre fraude em consignado.",
                relator="Des. Maria Santos"
            )
            
            sec1 = SectionNode(
                id="sec_001",
                parent_document_id="doc_001",
                section_type=SectionType.DECISAO,
                conteudo_limpo="Decis√£o sobre o empr√©stimo."
            )
            
            # Cria arestas
            sim_edge = SimilarityEdge.create_document_similarity(
                "doc_001", "doc_002", 0.75
            )
            
            hier_edge = HierarchicalEdge.create_document_section(
                "doc_001", "sec_001", 1
            )
            
            print_success("Pipeline simulado criado")
            print_info(f"  - Documentos: {doc1.id}, {doc2.id}")
            print_info(f"  - Se√ß√£o: {sec1.id}")
            print_info(f"  - Aresta similaridade: peso {sim_edge.weight}")
            print_info(f"  - Aresta hier√°rquica: peso {hier_edge.weight}")
            
            # Testa valida√ß√£o do schema
            from graph.models.nodes import NodeType
            errors1 = schema.validate_node(doc1)
            errors2 = schema.validate_edge(sim_edge, NodeType.DOCUMENT, NodeType.DOCUMENT)
            
            print_info(f"  - Erros valida√ß√£o doc1: {len(errors1)}")
            print_info(f"  - Erros valida√ß√£o aresta: {len(errors2)}")
            
            results['IntegrationPipeline'] = True
            
        except Exception as e:
            print_error(f"Erro no teste de integra√ß√£o: {e}")
            results['IntegrationPipeline'] = False
        
        # Teste 2: Compatibilidade de dados
        print_subsection("Teste Compatibilidade")
        try:
            # Testa se todos os tipos enum s√£o compat√≠veis
            from graph.models.nodes import NodeType, SectionType, EntityType
            from graph.models.edges import EdgeType, SimilarityType
            
            node_types = [t.value for t in NodeType]
            section_types = [t.value for t in SectionType]
            edge_types = [t.value for t in EdgeType]
            
            print_success("Enums carregados com sucesso")
            print_info(f"  - Tipos de n√≥: {node_types}")
            print_info(f"  - Tipos de se√ß√£o: {section_types}")
            print_info(f"  - Tipos de aresta: {edge_types}")
            
            # Testa serializa√ß√£o/desserializa√ß√£o
            doc_dict = doc1.to_dict()
            edge_dict = sim_edge.to_dict()
            
            print_info(f"  - Serializa√ß√£o doc: {len(doc_dict)} campos")
            print_info(f"  - Serializa√ß√£o edge: {len(edge_dict)} campos")
            
            results['Compatibility'] = True
            
        except Exception as e:
            print_error(f"Erro no teste de compatibilidade: {e}")
            results['Compatibility'] = False
        
        return results
        
    except ImportError as e:
        print_error(f"Erro de importa√ß√£o na integra√ß√£o: {e}")
        return {}

def generate_test_report(all_results: Dict[str, Dict[str, bool]]) -> Dict[str, Any]:
    """Gera relat√≥rio final dos testes"""
    
    total_tests = 0
    passed_tests = 0
    failed_tests = 0
    
    detailed_results = {}
    
    for category, tests in all_results.items():
        category_passed = sum(tests.values())
        category_total = len(tests)
        
        detailed_results[category] = {
            'passed': category_passed,
            'total': category_total,
            'success_rate': category_passed / category_total if category_total > 0 else 0,
            'details': tests
        }
        
        total_tests += category_total
        passed_tests += category_passed
    
    failed_tests = total_tests - passed_tests
    
    return {
        'summary': {
            'total_tests': total_tests,
            'passed_tests': passed_tests,
            'failed_tests': failed_tests,
            'success_rate': passed_tests / total_tests if total_tests > 0 else 0
        },
        'by_category': detailed_results,
        'timestamp': datetime.now().isoformat()
    }

def main():
    """Fun√ß√£o principal dos testes"""
    print("üöÄ INICIANDO TESTES DAS ETAPAS 1 e 2")
    print(f"üìÖ Data: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"üìÅ Diret√≥rio: {Path.cwd()}")
    
    start_time = time.time()
    
    # Executa todos os testes
    test_results = {}
    
    # Teste de importa√ß√µes
    import_results = test_imports()
    test_results['Imports'] = import_results
    
    # Se importa√ß√µes b√°sicas passaram, continua
    if import_results.get('graph.models.nodes', False):
        node_results = test_node_models()
        test_results['NodeModels'] = node_results
    else:
        print_error("‚ùå Pulando teste de n√≥s - importa√ß√£o falhou")
        test_results['NodeModels'] = {}
    
    if import_results.get('graph.models.edges', False):
        edge_results = test_edge_models()
        test_results['EdgeModels'] = edge_results
    else:
        print_error("‚ùå Pulando teste de arestas - importa√ß√£o falhou")
        test_results['EdgeModels'] = {}
    
    if import_results.get('graph.models.graph_schema', False):
        schema_results = test_graph_schema()
        test_results['GraphSchema'] = schema_results
    else:
        print_error("‚ùå Pulando teste de schema - importa√ß√£o falhou")
        test_results['GraphSchema'] = {}
    
    if import_results.get('graph.pipeline.preprocessing', False):
        preprocessing_results = test_preprocessing()
        test_results['Preprocessing'] = preprocessing_results
    else:
        print_error("‚ùå Pulando teste de preprocessamento - importa√ß√£o falhou")
        test_results['Preprocessing'] = {}
    
    # Teste de integra√ß√£o (se tudo passou)
    basic_imports_ok = all([
        import_results.get('graph.models.nodes', False),
        import_results.get('graph.models.edges', False),
        import_results.get('graph.models.graph_schema', False)
    ])
    
    if basic_imports_ok:
        integration_results = test_integration()
        test_results['Integration'] = integration_results
    else:
        print_error("‚ùå Pulando teste de integra√ß√£o - depend√™ncias falharam")
        test_results['Integration'] = {}
    
    # Gera relat√≥rio final
    end_time = time.time()
    execution_time = end_time - start_time
    
    print_section("RELAT√ìRIO FINAL DOS TESTES")
    
    report = generate_test_report(test_results)
    
    # Exibe sum√°rio
    summary = report['summary']
    print_info(f"‚è±Ô∏è Tempo de execu√ß√£o: {execution_time:.2f} segundos")
    print_info(f"üìä Total de testes: {summary['total_tests']}")
    print_success(f"‚úÖ Testes aprovados: {summary['passed_tests']}")
    
    if summary['failed_tests'] > 0:
        print_error(f"‚ùå Testes falharam: {summary['failed_tests']}")
    
    success_rate = summary['success_rate'] * 100
    print_info(f"üìà Taxa de sucesso: {success_rate:.1f}%")
    
    # Exibe detalhes por categoria
    print_subsection("Detalhes por Categoria")
    for category, details in report['by_category'].items():
        status = "‚úÖ" if details['success_rate'] == 1.0 else "‚ö†Ô∏è" if details['success_rate'] > 0.5 else "‚ùå"
        print(f"{status} {category}: {details['passed']}/{details['total']} ({details['success_rate']*100:.1f}%)")
        
        # Mostra testes que falharam
        failed_tests = [test for test, passed in details['details'].items() if not passed]
        if failed_tests:
            print(f"    Falharam: {', '.join(failed_tests)}")
    
    # Recomenda√ß√µes baseadas nos resultados
    print_subsection("Recomenda√ß√µes")
    
    if summary['success_rate'] >= 0.9:
        print_success("üéâ Excelente! Sistema est√° funcionando corretamente.")
        print_info("‚ú® Voc√™ pode prosseguir para a Etapa 3 com confian√ßa.")
    elif summary['success_rate'] >= 0.7:
        print_warning("‚ö†Ô∏è Maioria dos testes passou, mas h√° alguns problemas.")
        print_info("üîß Revise os erros antes de continuar.")
    else:
        print_error("‚ùå Muitos testes falharam. Sistema precisa de ajustes.")
        print_info("üõ†Ô∏è Corrija os problemas fundamentais antes de prosseguir.")
    
    # Diagn√≥sticos espec√≠ficos
    if not test_results['Imports'].get('graph.pipeline.preprocessing', False):
        print_warning("üíæ Preprocessamento n√£o p√¥de ser testado completamente.")
        print_info("   Isso pode ser devido ao banco n√£o estar rodando.")
        print_info("   Execute: cd docker && docker-compose up -d")
    
    if test_results['NodeModels'].get('DocumentNode', False) and test_results['EdgeModels'].get('SimilarityEdge', False):
        print_success("üèóÔ∏è Estruturas b√°sicas do grafo est√£o funcionais.")
    
    if test_results['GraphSchema'].get('GraphConfiguration', False):
        print_success("‚öôÔ∏è Sistema de configura√ß√£o est√° operacional.")
    
    # Pr√≥ximos passos
    print_subsection("Pr√≥ximos Passos")
    
    if summary['success_rate'] >= 0.8:
        print("üéØ Sistema validado! Pr√≥ximos passos recomendados:")
        print("   1. üöÄ Execute teste com dados reais do banco")
        print("   2. üìä Teste o preprocessamento com amostra pequena")
        print("   3. üèóÔ∏è Prosseguir para Etapa 3 (Extra√ß√£o de Se√ß√µes)")
        
        print("\nüí° Comando para testar com dados reais:")
        print("   python scripts/test_with_real_data.py")
    else:
        print("üîß Corrija os problemas encontrados:")
        print("   1. ‚úÖ Verifique se todos os arquivos foram criados")
        print("   2. üîç Revise os erros de importa√ß√£o")
        print("   3. üíæ Confirme se o banco est√° rodando")
        print("   4. üîÑ Execute o teste novamente")
    
    # Salva relat√≥rio detalhado
    try:
        import json
        report_file = project_root / "data" / "graph" / "test_report.json"
        report_file.parent.mkdir(parents=True, exist_ok=True)
        
        with open(report_file, 'w', encoding='utf-8') as f:
            json.dump(report, f, indent=2, ensure_ascii=False)
        
        print_info(f"üìÑ Relat√≥rio salvo em: {report_file}")
        
    except Exception as e:
        print_warning(f"‚ö†Ô∏è N√£o foi poss√≠vel salvar o relat√≥rio: {e}")
    
    print(f"\n{'='*80}")
    if summary['success_rate'] >= 0.8:
        print("üéâ TESTES CONCLU√çDOS COM SUCESSO!")
    else:
        print("‚ö†Ô∏è TESTES CONCLU√çDOS COM PROBLEMAS")
    print(f"{'='*80}")
    
    return report

if __name__ == "__main__":
    try:
        report = main()
        
        # Exit code baseado no sucesso
        success_rate = report['summary']['success_rate']
        if success_rate >= 0.8:
            sys.exit(0)  # Sucesso
        elif success_rate >= 0.5:
            sys.exit(1)  # Problemas menores
        else:
            sys.exit(2)  # Problemas s√©rios
            
    except KeyboardInterrupt:
        print("\n\n‚ö†Ô∏è Teste interrompido pelo usu√°rio")
        sys.exit(130)
    except Exception as e:
        print(f"\n\n‚ùå Erro inesperado durante os testes: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(3)